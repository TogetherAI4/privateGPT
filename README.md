# üîí PrivateGPT üìë

[![Tests](https://github.com/imartinez/privateGPT/actions/workflows/tests.yml/badge.svg)](https://github.com/imartinez/privateGPT/actions/workflows/tests.yml?query=branch%3Amain)
[![Website](https://img.shields.io/website?up_message=check%20it&down_message=down&url=https%3A%2F%2Fdocs.privategpt.dev%2F&label=Dokumentation)](https://docs.privategpt.dev/)

[![Discord](https://img.shields.io/discord/1164200432894234644?logo=discord&label=PrivateGPT)](https://discord.gg/bK6mRVpErU)
[![X (ehemals Twitter) Folgen](https://img.shields.io/twitter/follow/ZylonPrivateGPT)](https://twitter.com/ZylonPrivateGPT)


> Installations- & Nutzungsanleitungen: https://docs.privategpt.dev/
> 
> Tritt der Community bei: [Twitter](https://twitter.com/PrivateGPT_AI) & [Discord](https://discord.gg/bK6mRVpErU)

![Gradio UI](/fern/docs/assets/ui.png?raw=true)

PrivateGPT ist ein produktionsbereites KI-Projekt, das es Ihnen erm√∂glicht, Fragen zu Ihren Dokumenten mithilfe von Large Language Models (LLMs) zu stellen, auch in Szenarien ohne Internetverbindung. 100 % privat, keine Daten verlassen Ihre Ausf√ºhrungsumgebung zu irgendeinem Zeitpunkt.

Das Projekt bietet eine API an, die alle primitives bereitstellt, die zum Erstellen privater, kontextbewusster KI-Anwendungen erforderlich sind. Es folgt und erweitert den [OpenAI API-Standard](https://openai.com/blog/openai-api) und unterst√ºtzt sowohl normale als auch Streaming-Antworten.

Die API ist in zwei logische Bl√∂cke unterteilt:

**Hochrangige API**, die alle Komplexit√§t einer RAG (Retrieval Augmented Generation) Pipeline-Implementierung abstrahiert:
- Aufnahme von Dokumenten: Internes Management von Dokumentenparsen, Aufteilen, Metadatenextraktion, Einbettungsgenerierung und Speicherung.
- Chat & Vervollst√§ndigungen unter Verwendung von Kontext aus aufgenommenen Dokumenten: Abstrahierung der Abfrage des Kontexts, der Anregungsentwicklung und der Antwortgenerierung.

**Niedrigrangige API**, die es fortgeschrittenen Benutzern erm√∂glicht, ihre eigenen komplexen Pipelines zu implementieren:
- Einbettungsgenerierung: basierend auf einem Textst√ºck.
- Kontextbezogene Chunk-Abfrage: Gibt eine Abfrage zur√ºck und gibt die relevantesten Textst√ºcke aus den aufgenommenen Dokumenten zur√ºck.

Zus√§tzlich dazu wird ein funktionierender [Gradio UI](https://www.gradio.app/) Client bereitgestellt, um die API zu testen, zusammen mit einer Reihe n√ºtzlicher Tools wie Skript zum Massenmodell-Download, Skript zur Aufnahme, √úberwachung des Dokumentenordners usw.

> üëÇ **Brauchen Sie Hilfe bei der Anwendung von PrivateGPT f√ºr Ihren spezifischen Anwendungsfall?**
> [Lassen Sie es uns wissen](https://forms.gle/4cSDmH13RZBHV9at7)
> und wir werden versuchen zu helfen! Wir verbessern PrivateGPT durch Ihr Feedback.

## üéûÔ∏è √úberblick
HAFTUNGSAUSSCHLUSS: Dieses README wird nicht so h√§ufig aktualisiert wie die [Dokumentation](https://docs.privategpt.dev/).
Bitte schauen Sie dort f√ºr die neuesten Updates nach!

### Motivation hinter PrivateGPT
Generative KI ist ein Game Changer f√ºr unsere Gesellschaft, aber die Akzeptanz in Unternehmen aller Gr√∂√üen und datensensiblen Bereichen wie Gesundheitswesen oder Recht ist durch eine klare Sorge begrenzt: **Privatsph√§re**.
Die Unf√§higkeit, sicherzustellen, dass Ihre Daten vollst√§ndig unter Ihrer Kontrolle stehen, wenn Sie KI-Tools von Drittanbietern verwenden, ist ein Risiko, das sich diese Branchen nicht leisten k√∂nnen.

### Urversion
Die erste Version von PrivateGPT wurde im Mai 2023 als neuartiger Ansatz zur Bew√§ltigung der Datenschutzbedenken durch die Verwendung von LLMs auf eine vollst√§ndig offline Art und Weise eingef√ºhrt.

Diese Version, die schnell zu einem Standardprojekt f√ºr datenschutzsensible Setups wurde und als Keim f√ºr tausende lokal fokussierte generative KI-Projekte diente, war die Grundlage dessen, was PrivateGPT heute wird; daher eine einfachere und lehrreichere Implementierung, um die grundlegenden Konzepte zu verstehen, die erforderlich sind, um ein vollst√§ndig lokales - und daher privates - ChatGPT-√§hnliches Tool zu erstellen.

Wenn Sie weiterhin damit experimentieren m√∂chten, haben wir es im [Urversion-Zweig](https://github.com/imartinez/privateGPT/tree/primordial) des Projekts gespeichert.

> Es wird dringend empfohlen, eine saubere Kopie anzufertigen und diese neue Version von
PrivateGPT zu installieren, wenn Sie von der vorherigen, urzeitlichen Version kommen.

### Gegenwart und Zukunft von PrivateGPT
PrivateGPT entwickelt sich jetzt zu einem Gateway f√ºr generative KI-Modelle und primitives, einschlie√ülich
Vervollst√§ndigungen, Dokumentenaufnahme, RAG-Pipelines und anderen niedrigschwelligen Bausteinen.
Wir m√∂chten es jedem Entwickler erleichtern, KI-Anwendungen und -Erfahrungen zu erstellen, sowie eine geeignete umfangreiche Architektur f√ºr die Community bereitzustellen, um weiter beizutragen.

Bleiben Sie auf unsere [Ver√∂ffentlichungen](https://github.com/imartinez/privateGPT/releases) gespannt, um alle neuen Funktionen und √Ñnderungen zu sehen.

## üìÑ Dokumentation
Die vollst√§ndige Dokumentation zur Installation, Abh√§ngigkeiten, Konfiguration, Ausf√ºhrung des Servers, Bereitstellungsoptionen,
Aufnahme lokaler Dokumente, API-Details und UI-Funktionen finden Sie hier: https://docs.privategpt.dev/

## üß© Architektur
Konzeptionell ist PrivateGPT eine API, die eine RAG-Pipeline umh√ºllt und ihre
Primitives freilegt.
* Die API wurde unter Verwendung von [FastAPI](https://fastapi.tiangolo.com/) erstellt und folgt
 

 dem [API-Schema von OpenAI](https://platform.openai.com/docs/api-reference).
* Die RAG-Pipeline basiert auf [LlamaIndex](https://www.llamaindex.ai/).

Das Design von PrivateGPT erm√∂glicht es, sowohl die API als auch die
RAG-Implementierung einfach zu erweitern und anzupassen. Einige wichtige architektonische Entscheidungen sind:
* Dependency Injection, Entkopplung der verschiedenen Komponenten und Schichten.
* Verwendung von LlamaIndex-Abstraktionen wie `LLM`, `BaseEmbedding` oder `VectorStore`,
  was es sofort erm√∂glicht, die tats√§chlichen Implementierungen dieser Abstraktionen zu √§ndern.
* Einfachheit, Hinzuf√ºgen so weniger Schichten und neuer Abstraktionen wie m√∂glich.
* Einsatzbereit, Bereitstellung einer vollst√§ndigen Implementierung der API und RAG
  Pipeline.

Hauptbausteine:
* APIs sind in `private_gpt:server:<api>` definiert. Jedes Paket enth√§lt einen
  `<api>_router.py` (FastAPI-Schicht) und einen `<api>_service.py` (die
  Dienstimplementierung). Jeder *Service* verwendet LlamaIndex-Basisabstraktionen anstelle von spezifischen Implementierungen,
  Entkopplung der tats√§chlichen Implementierung von ihrer Verwendung.
* Komponenten sind in
  `private_gpt:components:<component>` platziert. Jede *Komponente* ist daf√ºr verantwortlich,
  tats√§chliche Implementierungen f√ºr die Basenabstraktionen bereitzustellen, die in den Services verwendet werden - zum Beispiel
  `LLMComponent` ist daf√ºr verantwortlich, eine tats√§chliche Implementierung eines `LLM` bereitzustellen
  (zum Beispiel `LlamaCPP` oder `OpenAI`).

## üí° Mitarbeit
Beitr√§ge sind willkommen! Um die Codequalit√§t zu gew√§hrleisten, haben wir mehrere Format- und
Typenpr√ºfungen aktiviert. F√ºhren Sie einfach `make check` aus, bevor Sie √Ñnderungen commiten, um sicherzustellen, dass Ihr Code in Ordnung ist.
Vergessen Sie nicht, Ihren Code zu testen! Sie finden einen Testsordner mit Hilfsprogrammen, und Sie k√∂nnen
Tests mit dem Befehl `make test` ausf√ºhren.

Sie wissen nicht, was Sie beitragen sollen? Hier ist das √∂ffentliche
[Projektboard](https://github.com/users/imartinez/projects/3) mit verschiedenen Ideen.

Gehen Sie zum Discord-Kanal
#contributors und bitten Sie um Schreibberechtigungen f√ºr dieses GitHub-Projekt.

## üí¨ Community
Treten Sie der Diskussion rund um PrivateGPT bei auf:
- [Twitter (aka X)](https://twitter.com/PrivateGPT_AI)
- [Discord](https://discord.gg/bK6mRVpErU)

## üìñ Zitierung
Wenn Sie PrivateGPT in einem Paper verwenden, schauen Sie sich die [Zitationsdatei](CITATION.cff) f√ºr die korrekte Zitierung an.  
Sie k√∂nnen auch die Schaltfl√§che "Dieses Repository zitieren" in diesem Repository verwenden, um die Zitierung in verschiedenen Formaten zu erhalten.

Hier sind ein paar Beispiele:

#### BibTeX
```bibtex
@software{Martinez_Toro_PrivateGPT_2023,
author = {Mart√≠nez Toro, Iv√°n and Gallego Vico, Daniel and Orgaz, Pablo},
license = {Apache-2.0},
month = may,
title = {{PrivateGPT}},
url = {https://github.com/imartinez/privateGPT},
year = {2023}
}
```

#### APA
```
Mart√≠nez Toro, I., Gallego Vico, D., & Orgaz, P. (2023). PrivateGPT [Computer software]. https://github.com/imartinez/privateGPT
```

## ü§ó Partner & Unterst√ºtzer
PrivateGPT wird aktiv unterst√ºtzt von den Teams hinter:
* [Qdrant](https://qdrant.tech/), Bereitstellung der Standard-Vektordatenbank
* [Fern](https://buildwithfern.com/), Bereitstellung von Dokumentation und SDKs
* [LlamaIndex](https://www.llamaindex.ai/), Bereitstellung des Basissystems und der Abstraktionen f√ºr RAG

Dieses Projekt wurde stark von anderen erstaunlichen Projekten beeinflusst und unterst√ºtzt wie
[LangChain](https://github.com/hwchase17/langchain),
[GPT4All](https://github.com/nomic-ai/gpt4all),
[LlamaCpp](https://github.com/ggerganov/llama.cpp),
[Chroma](https://www.trychroma.com/)
und [SentenceTransformers](https://www.sbert.net/).
